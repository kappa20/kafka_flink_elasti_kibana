services:
  # --- DATA INGESTION: Official Apache Zookeeper ---
  zookeeper:
    image: zookeeper:3.9.1
    container_name: zookeeper
    environment:
      ZOO_MY_ID: 1
    networks:
      - bigdata-network
    volumes:
      - zk_data:/data
      - zk_log:/datalog

  # --- DATA INGESTION: Official Apache Kafka ---
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      # IMPORTANT: This tells Kafka how to identify itself to different clients
      KAFKA_LISTENERS: EXTERNAL://:9092,INTERNAL://:29092
      KAFKA_ADVERTISED_LISTENERS: EXTERNAL://localhost:9092,INTERNAL://kafka:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: EXTERNAL:PLAINTEXT,INTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    networks:
      - bigdata-network
    volumes:
      - kafka_data:/var/lib/kafka/data

  # --- STREAM PROCESSING: Custom Apache Flink with Python ---
  flink-jobmanager:
    build:
      context: .
      dockerfile: Dockerfile.flink
    container_name: "flink-jobmanager"
    ports:
      - "8081:8081"
    command: jobmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
    networks:
      - bigdata-network
    volumes:
      - ./flink-sql-connector-kafka-3.0.1-1.18.jar:/opt/flink/lib/flink-sql-connector-kafka-3.0.1-1.18.jar
      - ./flink-sql-connector-elasticsearch7-3.0.1-1.17.jar:/opt/flink/lib/flink-sql-connector-elasticsearch7-3.0.1-1.17.jar
      - ./kafka_flink_elasticsearch_streaming_v2.py:/opt/flink/kafka_flink_elasticsearch_streaming_v2.py
      - ./word_count/kafka_flink_wordcount_v3.py:/opt/flink/kafka_flink_wordcount_v3.py
      - flink_data:/opt/flink/data

  flink-taskmanager:
    build:
      context: .
      dockerfile: Dockerfile.flink
    container_name: flink-taskmanager
    depends_on:
      - flink-jobmanager
    command: taskmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        taskmanager.numberOfTaskSlots: 2
    networks:
      - bigdata-network
    volumes:
      - ./flink-sql-connector-kafka-3.0.1-1.18.jar:/opt/flink/lib/flink-sql-connector-kafka-3.0.1-1.18.jar
      - ./flink-sql-connector-elasticsearch7-3.0.1-1.17.jar:/opt/flink/lib/flink-sql-connector-elasticsearch7-3.0.1-1.17.jar
      - ./kafka_flink_elasticsearch_streaming_v2.py:/opt/flink/kafka_flink_elasticsearch_streaming_v2.py
      - ./word_count/kafka_flink_wordcount_v3.py:/opt/flink/kafka_flink_wordcount_v3.py
      - flink_data:/opt/flink/data

  # --- INDEXING & VISUALIZATION: Elasticsearch & Kibana ---
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.10
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
    networks:
      - bigdata-network
    volumes:
      - es_data:/usr/share/elasticsearch/data

  kibana:
    image: docker.elastic.co/kibana/kibana:7.17.10
    container_name: kibana
    depends_on:
      - elasticsearch
    ports:
      - "5601:5601"
    environment:
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
    networks:
      - bigdata-network

# --- INFRASTRUCTURE ---
networks:
  bigdata-network:
    external: true

volumes:
  zk_data:
  zk_log:
  kafka_data:
  es_data:
  flink_data: